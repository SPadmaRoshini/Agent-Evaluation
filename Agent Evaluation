{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNoHBvxbUyBKp8gpbrdXjQE"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install evaluate transformers rouge_score"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"kaGUWLRR0xTH","executionInfo":{"status":"ok","timestamp":1754457813356,"user_tz":-330,"elapsed":11153,"user":{"displayName":"Padma Roshini S","userId":"01621893379350574116"}},"outputId":"b26e0373-23c7-47c0-a238-ecd7fba9d285"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.54.0)\n","Collecting rouge_score\n","  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.0.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.0.2)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.34.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (25.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.2)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n","Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.4.0)\n","Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (from rouge_score) (3.9.1)\n","Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.11/dist-packages (from rouge_score) (1.17.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.14)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.14.1)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.5)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.7.14)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (8.2.1)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk->rouge_score) (1.5.1)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.3)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n","Building wheels for collected packages: rouge_score\n","  Building wheel for rouge_score (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for rouge_score: filename=rouge_score-0.1.2-py3-none-any.whl size=24934 sha256=95833e3920b49ff159a14203a7e8adc9ea685f3764c1a0571e159eb4a69063bb\n","  Stored in directory: /root/.cache/pip/wheels/1e/19/43/8a442dc83660ca25e163e1bd1f89919284ab0d0c1475475148\n","Successfully built rouge_score\n","Installing collected packages: rouge_score\n","Successfully installed rouge_score-0.1.2\n"]}]},{"cell_type":"code","source":["import time\n","import uuid\n","import random\n","import pandas as pd\n","from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n","from evaluate import load\n","\n","# ----------------------------\n","# 1. Load Falcon model\n","# ----------------------------\n","print(\"Device set to use cpu\")\n","model_name = \"tiiuae/falcon-rw-1b\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForCausalLM.from_pretrained(model_name)\n","generator = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, device=-1)\n","\n","# Metrics\n","bleu = load(\"bleu\")\n","rouge = load(\"rouge\")\n","\n","# ----------------------------\n","# 2. Tools Layer\n","# ----------------------------\n","def search_tool(task):\n","    return f\"Found simulated insights for '{task}' including references and best practices.\"\n","\n","def analysis_tool(task):\n","    return f\"Completed simulated analysis of '{task}' and extracted trends & insights.\"\n","\n","def default_tool(task):\n","    return f\"Basic simulated response for '{task}'.\"\n","\n","def nlp_tool(task):\n","    return \"NLP Analysis → Keywords: ['product', 'improvement', 'potential'] | Sentiment: positive\"\n","\n","def stats_tool(task):\n","    return \"Stats → Mean: 7.00, StdDev: 3.42, Max: 12, Min: 2\"\n","\n","TOOLS = {\n","    \"search\": search_tool,\n","    \"analysis\": analysis_tool,\n","    \"default\": default_tool,\n","    \"nlp\": nlp_tool,\n","    \"stats\": stats_tool,\n","}\n","\n","# ----------------------------\n","# 3. Metric Computation\n","# ----------------------------\n","def compute_metrics(prediction, reference):\n","    pred_tokens = prediction.lower().split()\n","    ref_tokens = reference.lower().split()\n","\n","    # BLEU\n","    bleu_score = bleu.compute(predictions=[prediction], references=[[reference]])['bleu']\n","\n","    # ROUGE-L\n","    rouge_score = rouge.compute(predictions=[prediction], references=[reference])['rougeL']\n","\n","    # F1\n","    common_tokens = set(pred_tokens) & set(ref_tokens)\n","    if len(pred_tokens) > 0 and len(ref_tokens) > 0:\n","        precision = len(common_tokens) / len(pred_tokens)\n","        recall = len(common_tokens) / len(ref_tokens)\n","        f1_score = (2 * precision * recall) / (precision + recall + 1e-8)\n","    else:\n","        f1_score = 0.0\n","\n","    return {\"BLEU\": round(bleu_score, 3), \"ROUGE-L\": round(rouge_score, 3), \"F1\": round(f1_score, 3)}\n","\n","# ----------------------------\n","# 4. Judgment & Toxicity Simulation\n","# ----------------------------\n","def judge_output(answer, error_occurred=False):\n","    if error_occurred:\n","        return {\"label\": \"FAIL\", \"score\": 0.0}\n","    labels = [\"POSITIVE\", \"NEUTRAL\"]\n","    return {\"label\": random.choice(labels), \"score\": round(random.uniform(0.85, 0.97), 3)}\n","\n","def simulate_toxicity(answer, error_occurred=False):\n","    if error_occurred:\n","        return \"error\"\n","    return random.choice([\"safe\", \"toxic\", \"error\"])\n","\n","# ----------------------------\n","# 5. Agent Execution\n","# ----------------------------\n","def run_agent_task(task, tool_key, simulate_error=False):\n","    start_time = time.time()\n","    error_occurred = False\n","    tool_output, agent_answer = None, None\n","\n","    try:\n","        # Tool execution\n","        tool_func = TOOLS.get(tool_key, default_tool)\n","        tool_output = tool_func(task)\n","\n","        # Simulate error\n","        if simulate_error:\n","            raise RuntimeError(\"Simulated tool failure\")\n","\n","        # Generate LLM response\n","        agent_answer = generator(\n","            f\"Task: {task}\\nTool Output: {tool_output}\\nGenerate answer:\",\n","            max_length=120,\n","            max_new_tokens=256,\n","            num_return_sequences=1,\n","            do_sample=True,\n","            truncation=True\n","        )[0]['generated_text']\n","\n","    except Exception as e:\n","        error_occurred = True\n","        agent_answer = f\"Simulated error for: {task}...\"\n","        tool_output = None\n","\n","    latency = round(time.time() - start_time, 2) if not error_occurred else 0.0\n","    judgment = judge_output(agent_answer, error_occurred)\n","    metrics = compute_metrics(agent_answer, task)  # <-- Compare with task as reference\n","    toxicity = simulate_toxicity(agent_answer, error_occurred)\n","\n","    # Log single-task result\n","    print(f\"\\n--- Task: {task} ---\")\n","    print(f\"Status: {'completed' if not error_occurred else 'failed'}, Latency: {latency}s, Error: {error_occurred}\")\n","    print(f\"Tool Output: {tool_output}\")\n","    print(f\"Agent Answer: {agent_answer[:250]}...\")\n","    print(f\"Judge: {judgment}\")\n","    print(f\"Metrics: {metrics}, Toxicity: {toxicity}\")\n","\n","    return {\n","        \"task_id\": str(uuid.uuid4()),\n","        \"task_description\": task,\n","        \"status\": \"completed\" if not error_occurred else \"failed\",\n","        \"latency\": latency,\n","        \"error_occurred\": error_occurred,\n","        \"agent_answer\": agent_answer,\n","        \"judgment\": judgment,\n","        \"metrics\": metrics,\n","        \"toxicity\": toxicity\n","    }\n","\n","# ----------------------------\n","# 6. Run Multiple Tasks\n","# ----------------------------\n","tasks = [\n","    (\"Search for 'AI agent observability best practices'\", \"search\", False),\n","    (\"Analyze 'customer feedback survey data'\", \"analysis\", False),\n","    (\"Run NLP on review text\", \"nlp\", False),\n","    (\"Compute statistics for sample data\", \"stats\", False),\n","    (\"Just say hello to the user\", \"default\", False),\n","    (\"Simulate an error during tool use\", \"analysis\", True),\n","]\n","\n","task_logs = [run_agent_task(*t) for t in tasks]\n","\n","# ----------------------------\n","# 7. Display Summary\n","# ----------------------------\n","df = pd.DataFrame(task_logs)\n","print(\"\\n=== Agent Task Evaluation Summary ===\")\n","print(df[[\n","    \"task_description\", \"status\", \"latency\", \"error_occurred\",\n","    \"judgment\", \"metrics\", \"toxicity\"\n","]])\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aXZAwOkK0YSx","executionInfo":{"status":"ok","timestamp":1754458546262,"user_tz":-330,"elapsed":726432,"user":{"displayName":"Padma Roshini S","userId":"01621893379350574116"}},"outputId":"dd168e3a-f301-478f-f137-0319c8ba47bc"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Device set to use cpu\n"]},{"output_type":"stream","name":"stderr","text":["Device set to use cpu\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n","Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Task: Search for 'AI agent observability best practices' ---\n","Status: completed, Latency: 140.41s, Error: False\n","Tool Output: Found simulated insights for 'Search for 'AI agent observability best practices'' including references and best practices.\n","Agent Answer: Task: Search for 'AI agent observability best practices'\n","Tool Output: Found simulated insights for 'Search for 'AI agent observability best practices'' including references and best practices.\n","Generate answer:\n","Search for 'AI agent observability best ...\n","Judge: {'label': 'NEUTRAL', 'score': 0.917}\n","Metrics: {'BLEU': 0.028, 'ROUGE-L': np.float64(0.071), 'F1': 0.071}, Toxicity: safe\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Task: Analyze 'customer feedback survey data' ---\n","Status: completed, Latency: 139.03s, Error: False\n","Tool Output: Completed simulated analysis of 'Analyze 'customer feedback survey data'' and extracted trends & insights.\n","Agent Answer: Task: Analyze 'customer feedback survey data'\n","Tool Output: Completed simulated analysis of 'Analyze 'customer feedback survey data'' and extracted trends & insights.\n","Generate answer:\n","The following report is generated for the selected project.\n","Note: A...\n","Judge: {'label': 'NEUTRAL', 'score': 0.888}\n","Metrics: {'BLEU': 0.015, 'ROUGE-L': np.float64(0.052), 'F1': 0.051}, Toxicity: toxic\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Task: Run NLP on review text ---\n","Status: completed, Latency: 137.07s, Error: False\n","Tool Output: NLP Analysis → Keywords: ['product', 'improvement', 'potential'] | Sentiment: positive\n","Agent Answer: Task: Run NLP on review text\n","Tool Output: NLP Analysis → Keywords: ['product', 'improvement', 'potential'] | Sentiment: positive\n","Generate answer:\n","The first two keywords are of a similar length and have similar meanings, but the third is significantly...\n","Judge: {'label': 'NEUTRAL', 'score': 0.956}\n","Metrics: {'BLEU': 0.015, 'ROUGE-L': np.float64(0.057), 'F1': 0.053}, Toxicity: toxic\n"]},{"output_type":"stream","name":"stderr","text":["Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n","Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"]},{"output_type":"stream","name":"stdout","text":["\n","--- Task: Compute statistics for sample data ---\n","Status: completed, Latency: 139.43s, Error: False\n","Tool Output: Stats → Mean: 7.00, StdDev: 3.42, Max: 12, Min: 2\n","Agent Answer: Task: Compute statistics for sample data\n","Tool Output: Stats → Mean: 7.00, StdDev: 3.42, Max: 12, Min: 2\n","Generate answer:\n","Sample data: [2x3]\n","Results:\n","Mean: 7.00\n","StdDev: 3.42\n","Max: 12\n","Min: 2\n","Max: 12\n","Max: 12\n","The mean of [2x3] is 7.00.\n","A standard deviatio...\n","Judge: {'label': 'NEUTRAL', 'score': 0.873}\n","Metrics: {'BLEU': 0.015, 'ROUGE-L': np.float64(0.057), 'F1': 0.06}, Toxicity: toxic\n","\n","--- Task: Just say hello to the user ---\n","Status: completed, Latency: 143.51s, Error: False\n","Tool Output: Basic simulated response for 'Just say hello to the user'.\n","Agent Answer: Task: Just say hello to the user\n","Tool Output: Basic simulated response for 'Just say hello to the user'.\n","Generate answer:\n","- [{\"Hello\":\"Hello\"}]\n","- [{\"Hello\":\"Hello\"}]\n","- [{\"Hello\":\"Hello\"}]\n","- [{\"Hello\":\"Hello\"}]\n","- [{\"Hello\":\"Hello\"}]\n","- [{\"Hello\":\"Hello...\n","Judge: {'label': 'POSITIVE', 'score': 0.884}\n","Metrics: {'BLEU': 0.012, 'ROUGE-L': np.float64(0.145), 'F1': 0.141}, Toxicity: toxic\n","\n","--- Task: Simulate an error during tool use ---\n","Status: failed, Latency: 0.0s, Error: True\n","Tool Output: None\n","Agent Answer: Simulated error for: Simulate an error during tool use......\n","Judge: {'label': 'FAIL', 'score': 0.0}\n","Metrics: {'BLEU': 0.381, 'ROUGE-L': np.float64(0.8), 'F1': 0.667}, Toxicity: error\n","\n","=== Agent Task Evaluation Summary ===\n","                                    task_description     status  latency  \\\n","0  Search for 'AI agent observability best practi...  completed   140.41   \n","1            Analyze 'customer feedback survey data'  completed   139.03   \n","2                             Run NLP on review text  completed   137.07   \n","3                 Compute statistics for sample data  completed   139.43   \n","4                         Just say hello to the user  completed   143.51   \n","5                  Simulate an error during tool use     failed     0.00   \n","\n","   error_occurred                               judgment  \\\n","0           False   {'label': 'NEUTRAL', 'score': 0.917}   \n","1           False   {'label': 'NEUTRAL', 'score': 0.888}   \n","2           False   {'label': 'NEUTRAL', 'score': 0.956}   \n","3           False   {'label': 'NEUTRAL', 'score': 0.873}   \n","4           False  {'label': 'POSITIVE', 'score': 0.884}   \n","5            True        {'label': 'FAIL', 'score': 0.0}   \n","\n","                                          metrics toxicity  \n","0  {'BLEU': 0.028, 'ROUGE-L': 0.071, 'F1': 0.071}     safe  \n","1  {'BLEU': 0.015, 'ROUGE-L': 0.052, 'F1': 0.051}    toxic  \n","2  {'BLEU': 0.015, 'ROUGE-L': 0.057, 'F1': 0.053}    toxic  \n","3   {'BLEU': 0.015, 'ROUGE-L': 0.057, 'F1': 0.06}    toxic  \n","4  {'BLEU': 0.012, 'ROUGE-L': 0.145, 'F1': 0.141}    toxic  \n","5    {'BLEU': 0.381, 'ROUGE-L': 0.8, 'F1': 0.667}    error  \n"]}]}]}